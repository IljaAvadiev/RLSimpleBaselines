{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from algorithms.deeprl.dqn.agent import DQN\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQN(env=env,\n",
    "            double=True,\n",
    "            duelling=True, \n",
    "            activation=F.relu, \n",
    "            optimizer=optim.RMSprop, \n",
    "            alpha=0.0001, \n",
    "            gamma=0.99, \n",
    "            epsilon_start=1, \n",
    "            epsilon_end=0.05, \n",
    "            epsilon_decay=0.000035,\n",
    "            tau=0.001,\n",
    "            max_memory_size=50000, \n",
    "            batch_size=64,\n",
    "            max_episodes=1000,\n",
    "            warmup=100,\n",
    "            replace_steps=1,\n",
    "            seed=1,\n",
    "            log=True,\n",
    "            dir='tmp', \n",
    "            name='LunarLander-DQN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 100\n",
      "Step: 11212\n",
      "Evaluation Reward: -180.63914298927958\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -121.18670223762254\n",
      "Eval Mean: -242.87607893336713\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 101\n",
      "Step: 11339\n",
      "Evaluation Reward: -259.8575805900698\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -120.1904633151862\n",
      "Eval Mean: -238.08516609038026\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 102\n",
      "Step: 11717\n",
      "Evaluation Reward: -355.81588980757215\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -120.46063244822625\n",
      "Eval Mean: -236.35331423919305\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 103\n",
      "Step: 11841\n",
      "Evaluation Reward: -387.7286097237811\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -119.13406337770417\n",
      "Eval Mean: -233.03365756135656\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 104\n",
      "Step: 11976\n",
      "Evaluation Reward: -137.31297079630812\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -119.6780269285326\n",
      "Eval Mean: -228.15865818642658\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 105\n",
      "Step: 12082\n",
      "Evaluation Reward: -379.358875276602\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -116.7258480775559\n",
      "Eval Mean: -225.47832129812187\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 106\n",
      "Step: 12281\n",
      "Evaluation Reward: -129.84775732481242\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -114.01933874344878\n",
      "Eval Mean: -221.2426428505145\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 107\n",
      "Step: 12484\n",
      "Evaluation Reward: -426.4397930338454\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -113.93617606264355\n",
      "Eval Mean: -217.7467046767916\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 108\n",
      "Step: 12633\n",
      "Evaluation Reward: -281.0167885514235\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -113.06549283411401\n",
      "Eval Mean: -212.0750767977554\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 109\n",
      "Step: 12792\n",
      "Evaluation Reward: -281.94907081747965\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -111.29853846681961\n",
      "Eval Mean: -207.33065907341873\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 110\n",
      "Step: 12866\n",
      "Evaluation Reward: -382.3663638525694\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -110.6749758253458\n",
      "Eval Mean: -204.25713073195607\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 111\n",
      "Step: 12952\n",
      "Evaluation Reward: -348.3083414471164\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -109.74002736247452\n",
      "Eval Mean: -203.3827082429315\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 112\n",
      "Step: 13044\n",
      "Evaluation Reward: -213.30855712809023\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -107.8818187232807\n",
      "Eval Mean: -199.7213948612235\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 113\n",
      "Step: 13243\n",
      "Evaluation Reward: -87.59444607068147\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -106.7146879277287\n",
      "Eval Mean: -197.2910971564097\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 114\n",
      "Step: 14243\n",
      "Evaluation Reward: -220.93485466814678\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -105.55462622434352\n",
      "Eval Mean: -195.0575296354708\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 115\n",
      "Step: 14493\n",
      "Evaluation Reward: -271.3852223461537\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -106.08131374406807\n",
      "Eval Mean: -194.3531024472976\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 116\n",
      "Step: 14640\n",
      "Evaluation Reward: -235.8987284454109\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -107.11751339957696\n",
      "Eval Mean: -193.92732732953573\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 117\n",
      "Step: 15201\n",
      "Evaluation Reward: -357.8052269450804\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -109.71488074068786\n",
      "Eval Mean: -195.0138916057401\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 118\n",
      "Step: 16201\n",
      "Evaluation Reward: -259.18750333968774\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -107.83784961006535\n",
      "Eval Mean: -195.0315038566991\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 119\n",
      "Step: 17201\n",
      "Evaluation Reward: -163.2644718286205\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -107.79487931768041\n",
      "Eval Mean: -193.8529760754986\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 120\n",
      "Step: 17624\n",
      "Evaluation Reward: -217.63879220209515\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.02915158261285\n",
      "Eval Mean: -194.00824453330316\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 121\n",
      "Step: 18624\n",
      "Evaluation Reward: -289.2467899326226\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.37381917976232\n",
      "Eval Mean: -193.5609883813635\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 122\n",
      "Step: 19624\n",
      "Evaluation Reward: -139.43804096863687\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.36872932971164\n",
      "Eval Mean: -193.13030577324633\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 123\n",
      "Step: 20624\n",
      "Evaluation Reward: -191.6748920812896\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -102.9681671910011\n",
      "Eval Mean: -192.63363775258924\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 124\n",
      "Step: 21294\n",
      "Evaluation Reward: -282.10823611403987\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.83257315750332\n",
      "Eval Mean: -194.43721265310967\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 125\n",
      "Step: 21646\n",
      "Evaluation Reward: -197.9371789103841\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -105.0733243348934\n",
      "Eval Mean: -194.9425277778575\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 126\n",
      "Step: 22646\n",
      "Evaluation Reward: -124.93730272099839\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.69714153121717\n",
      "Eval Mean: -194.8446703295884\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 127\n",
      "Step: 23131\n",
      "Evaluation Reward: -66.33626175159063\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -105.13424332781504\n",
      "Eval Mean: -194.1769415299677\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 128\n",
      "Step: 23692\n",
      "Evaluation Reward: -156.4572476766582\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.9576584842087\n",
      "Eval Mean: -194.7101062205883\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 129\n",
      "Step: 24169\n",
      "Evaluation Reward: -76.27546955366019\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -105.21005080263589\n",
      "Eval Mean: -195.29713217259786\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 130\n",
      "Step: 25087\n",
      "Evaluation Reward: -218.1802095631729\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -106.86053182883452\n",
      "Eval Mean: -196.46107226850566\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 131\n",
      "Step: 25424\n",
      "Evaluation Reward: -230.53846696431947\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -106.56581615583184\n",
      "Eval Mean: -197.19356937515394\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 132\n",
      "Step: 26424\n",
      "Evaluation Reward: -102.70687677949894\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -106.86155993135782\n",
      "Eval Mean: -197.30773456165107\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 133\n",
      "Step: 26975\n",
      "Evaluation Reward: -129.93578254299194\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -107.21183744099737\n",
      "Eval Mean: -196.94042218858897\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 134\n",
      "Step: 27975\n",
      "Evaluation Reward: -53.04087622758098\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -105.37272693689097\n",
      "Eval Mean: -196.49192550815096\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 135\n",
      "Step: 28975\n",
      "Evaluation Reward: -131.3758871990677\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -106.1729570580258\n",
      "Eval Mean: -195.90044665387438\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 136\n",
      "Step: 29975\n",
      "Evaluation Reward: -109.34108936647262\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -105.87455236071428\n",
      "Eval Mean: -194.73907421600003\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 137\n",
      "Step: 30858\n",
      "Evaluation Reward: -156.2809695792928\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.13357047973199\n",
      "Eval Mean: -195.07628463126107\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 138\n",
      "Step: 31486\n",
      "Evaluation Reward: -96.88599994718925\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -104.3994549562169\n",
      "Eval Mean: -193.73878044151442\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 139\n",
      "Step: 32010\n",
      "Evaluation Reward: -65.77375447260748\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -102.61531407260351\n",
      "Eval Mean: -192.42897448920186\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 140\n",
      "Step: 33010\n",
      "Evaluation Reward: -59.478621424983395\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -101.99251492989684\n",
      "Eval Mean: -191.3864360754868\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 141\n",
      "Step: 34010\n",
      "Evaluation Reward: -21.1425658147164\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -101.33949780035658\n",
      "Eval Mean: -190.0204051746059\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 142\n",
      "Step: 35010\n",
      "Evaluation Reward: -70.45827354872354\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -100.41515668071905\n",
      "Eval Mean: -188.83022332420228\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 143\n",
      "Step: 36010\n",
      "Evaluation Reward: -33.63383737615248\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -100.30741760865244\n",
      "Eval Mean: -187.69807834650913\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 144\n",
      "Step: 37010\n",
      "Evaluation Reward: -26.091207185261634\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -99.90367303248117\n",
      "Eval Mean: -185.8059719275383\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 145\n",
      "Step: 38010\n",
      "Evaluation Reward: -14.403239917176446\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -99.87699875140126\n",
      "Eval Mean: -183.78315979496082\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 146\n",
      "Step: 39010\n",
      "Evaluation Reward: -37.89747205230554\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -100.19601959202751\n",
      "Eval Mean: -182.02630823859477\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 147\n",
      "Step: 40010\n",
      "Evaluation Reward: -29.72987947900894\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -98.82207577105983\n",
      "Eval Mean: -180.3880915898745\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 148\n",
      "Step: 41010\n",
      "Evaluation Reward: -60.53307856732645\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -99.47960060747569\n",
      "Eval Mean: -180.72871713047826\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 149\n",
      "Step: 42010\n",
      "Evaluation Reward: -92.8986135687335\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -97.92175426485605\n",
      "Eval Mean: -179.89142799953385\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 150\n",
      "Step: 43010\n",
      "Evaluation Reward: -30.624644031446568\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -96.07515705545005\n",
      "Eval Mean: -178.51678931283814\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 151\n",
      "Step: 44010\n",
      "Evaluation Reward: -1.7955707445999116\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -95.85040865769543\n",
      "Eval Mean: -175.03229369411795\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 152\n",
      "Step: 45010\n",
      "Evaluation Reward: -33.506920489785024\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -93.94180593426388\n",
      "Eval Mean: -173.7965505622211\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 153\n",
      "Step: 46010\n",
      "Evaluation Reward: -16.786891413180765\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -92.47872049773683\n",
      "Eval Mean: -172.20725322051564\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 154\n",
      "Step: 47010\n",
      "Evaluation Reward: -77.73767256998838\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -89.50231438382039\n",
      "Eval Mean: -170.70882194010233\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 155\n",
      "Step: 48010\n",
      "Evaluation Reward: -12.770513026463517\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -88.92991232266755\n",
      "Eval Mean: -168.4920034114488\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 156\n",
      "Step: 49010\n",
      "Evaluation Reward: -9.499746810866293\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -88.88550026596282\n",
      "Eval Mean: -166.2862244415301\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 157\n",
      "Step: 50010\n",
      "Evaluation Reward: -39.44555777416136\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -87.72662467294833\n",
      "Eval Mean: -165.34581578550828\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 158\n",
      "Step: 51010\n",
      "Evaluation Reward: -16.665514262248063\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -86.44045471072059\n",
      "Eval Mean: -165.04314522669492\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 159\n",
      "Step: 52010\n",
      "Evaluation Reward: -35.497560725418\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -86.68348579082462\n",
      "Eval Mean: -164.26950373820128\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 160\n",
      "Step: 53010\n",
      "Evaluation Reward: -46.26921898944764\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -87.14913995485216\n",
      "Eval Mean: -162.95654646984775\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 161\n",
      "Step: 54010\n",
      "Evaluation Reward: -24.3594370359654\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -87.0955937052117\n",
      "Eval Mean: -162.57588267948483\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 162\n",
      "Step: 55010\n",
      "Evaluation Reward: -45.19171454422903\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -85.30516638785562\n",
      "Eval Mean: -160.49773936702863\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 163\n",
      "Step: 56010\n",
      "Evaluation Reward: -25.01952515053436\n",
      "Best Evaluation Reward: 59.4540614093564\n",
      "Train Mean: -85.01215882875164\n",
      "Eval Mean: -158.34065315067156\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 164\n",
      "Step: 57010\n",
      "Evaluation Reward: 156.95965999377853\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -83.38934557407634\n",
      "Eval Mean: -154.58711061784086\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 165\n",
      "Step: 58010\n",
      "Evaluation Reward: -43.29531465326681\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -82.67130249486014\n",
      "Eval Mean: -150.4647995001829\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 166\n",
      "Step: 59010\n",
      "Evaluation Reward: -15.537883404058617\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -81.76687616105444\n",
      "Eval Mean: -148.82794197441805\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 167\n",
      "Step: 60010\n",
      "Evaluation Reward: -26.816267502394943\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -81.05391674798666\n",
      "Eval Mean: -147.0957833333024\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 168\n",
      "Step: 61010\n",
      "Evaluation Reward: -20.622874655240203\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -80.42885854976548\n",
      "Eval Mean: -145.52821514297295\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 169\n",
      "Step: 62010\n",
      "Evaluation Reward: -12.942668754272525\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -79.88772474458914\n",
      "Eval Mean: -145.15190315088867\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 170\n",
      "Step: 63010\n",
      "Evaluation Reward: -52.35762911385035\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -79.21054679326134\n",
      "Eval Mean: -145.09658778002301\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 171\n",
      "Step: 64010\n",
      "Evaluation Reward: -101.72606264360202\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -77.7406593970087\n",
      "Eval Mean: -143.96211862128462\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 172\n",
      "Step: 64761\n",
      "Evaluation Reward: -27.767319045564772\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -73.61866554352513\n",
      "Eval Mean: -142.2924448241921\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 173\n",
      "Step: 65761\n",
      "Evaluation Reward: -29.543440954578074\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -70.58367068306397\n",
      "Eval Mean: -140.66097322737085\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 174\n",
      "Step: 66761\n",
      "Evaluation Reward: -45.481125214990364\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -69.93895122121788\n",
      "Eval Mean: -139.70972358673887\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 175\n",
      "Step: 67761\n",
      "Evaluation Reward: 0.9952660101858779\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -69.09224451617942\n",
      "Eval Mean: -137.47221962947714\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 176\n",
      "Step: 68761\n",
      "Evaluation Reward: -12.875789604259747\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -68.80696714618799\n",
      "Eval Mean: -135.76272582341417\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 177\n",
      "Step: 69761\n",
      "Evaluation Reward: -28.83122349100767\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -68.38447823922775\n",
      "Eval Mean: -134.72834685850495\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 178\n",
      "Step: 70761\n",
      "Evaluation Reward: -15.921442356814989\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -67.2300557043625\n",
      "Eval Mean: -132.95794905722295\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 179\n",
      "Step: 71761\n",
      "Evaluation Reward: -33.29441308993206\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -66.76713959951502\n",
      "Eval Mean: -133.19895826611162\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 180\n",
      "Step: 72761\n",
      "Evaluation Reward: -54.801406788514875\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -65.74159363365506\n",
      "Eval Mean: -134.34151294809033\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 181\n",
      "Step: 73761\n",
      "Evaluation Reward: -21.318471748463438\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -65.31250906290443\n",
      "Eval Mean: -132.75468502014678\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 182\n",
      "Step: 74761\n",
      "Evaluation Reward: 30.297097579850096\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -62.62070235877391\n",
      "Eval Mean: -131.53230711759113\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 183\n",
      "Step: 75759\n",
      "Evaluation Reward: -62.8517442655013\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -61.86187451597831\n",
      "Eval Mean: -130.24842486427758\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 184\n",
      "Step: 76759\n",
      "Evaluation Reward: -42.38200551602897\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -61.78148133713392\n",
      "Eval Mean: -129.0998773936286\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 185\n",
      "Step: 77759\n",
      "Evaluation Reward: -47.5760108826975\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -61.55808761278277\n",
      "Eval Mean: -127.00960665475813\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 186\n",
      "Step: 78203\n",
      "Evaluation Reward: -31.10346328718362\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -58.296662775297044\n",
      "Eval Mean: -126.02549599988888\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 187\n",
      "Step: 79203\n",
      "Evaluation Reward: -42.230183287991984\n",
      "Best Evaluation Reward: 156.95965999377853\n",
      "Train Mean: -57.05179733304369\n",
      "Eval Mean: -124.81847946107257\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 188\n",
      "Step: 80203\n",
      "Evaluation Reward: 178.5035458241546\n",
      "Best Evaluation Reward: 178.5035458241546\n",
      "Train Mean: -55.72286299558567\n",
      "Eval Mean: -119.77523393951478\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 189\n",
      "Step: 81203\n",
      "Evaluation Reward: -41.31676896323436\n",
      "Best Evaluation Reward: 178.5035458241546\n",
      "Train Mean: -54.97469739483572\n",
      "Eval Mean: -118.38992805612071\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 190\n",
      "Step: 82203\n",
      "Evaluation Reward: -77.84753151022416\n",
      "Best Evaluation Reward: 178.5035458241546\n",
      "Train Mean: -54.69221789839554\n",
      "Eval Mean: -117.21634882580247\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 191\n",
      "Step: 83203\n",
      "Evaluation Reward: -2.6638992657665153\n",
      "Best Evaluation Reward: 178.5035458241546\n",
      "Train Mean: -53.105020098920455\n",
      "Eval Mean: -115.23414740667579\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 192\n",
      "Step: 84203\n",
      "Evaluation Reward: -52.80006364751837\n",
      "Best Evaluation Reward: 178.5035458241546\n",
      "Train Mean: -52.17099729506698\n",
      "Eval Mean: -112.89859160136155\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 193\n",
      "Step: 85203\n",
      "Evaluation Reward: 196.261988382798\n",
      "Best Evaluation Reward: 196.261988382798\n",
      "Train Mean: -52.586963020640205\n",
      "Eval Mean: -108.62139937849977\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 194\n",
      "Step: 86203\n",
      "Evaluation Reward: 197.73556473970118\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -51.93226149367791\n",
      "Eval Mean: -104.66140339245263\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 195\n",
      "Step: 87203\n",
      "Evaluation Reward: -32.257976172300936\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -52.132475375413186\n",
      "Eval Mean: -101.91464426523513\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 196\n",
      "Step: 88073\n",
      "Evaluation Reward: 183.79160551285293\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -49.53358805070295\n",
      "Eval Mean: -99.18654497183368\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 197\n",
      "Step: 89073\n",
      "Evaluation Reward: -9.014749958729917\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -49.984886439846676\n",
      "Eval Mean: -97.18381057203281\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 198\n",
      "Step: 90073\n",
      "Evaluation Reward: -3.117943397796356\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -49.97895732111847\n",
      "Eval Mean: -95.62967008219746\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 199\n",
      "Step: 91073\n",
      "Evaluation Reward: -9.006440511319715\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -49.304570715702546\n",
      "Eval Mean: -93.10324981683405\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 200\n",
      "Step: 92072\n",
      "Evaluation Reward: 175.86884905146522\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -47.44268609087373\n",
      "Eval Mean: -89.53816989642662\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 201\n",
      "Step: 92405\n",
      "Evaluation Reward: -14.867583798350042\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -43.92515035695004\n",
      "Eval Mean: -87.08826992850943\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 202\n",
      "Step: 93405\n",
      "Evaluation Reward: -39.722258223829755\n",
      "Best Evaluation Reward: 197.73556473970118\n",
      "Train Mean: -43.07002985755493\n",
      "Eval Mean: -83.92733361267202\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 203\n",
      "Step: 94405\n",
      "Evaluation Reward: 269.849213014366\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -43.731808453107334\n",
      "Eval Mean: -77.35155538529052\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 204\n",
      "Step: 94727\n",
      "Evaluation Reward: -56.848633176724974\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -39.9472719783668\n",
      "Eval Mean: -76.54691200909471\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 205\n",
      "Step: 95562\n",
      "Evaluation Reward: 189.88278816892216\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -38.99217212118147\n",
      "Eval Mean: -70.85449537463947\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 206\n",
      "Step: 96562\n",
      "Evaluation Reward: -61.43588447809738\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -38.53185260764038\n",
      "Eval Mean: -70.17037664617231\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 207\n",
      "Step: 97562\n",
      "Evaluation Reward: -33.83738614723447\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -37.9026218042186\n",
      "Eval Mean: -66.2443525773062\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 208\n",
      "Step: 98562\n",
      "Evaluation Reward: -28.95449574338847\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -37.53083117245627\n",
      "Eval Mean: -63.72372964922585\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 209\n",
      "Step: 99562\n",
      "Evaluation Reward: -37.81665619601291\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -36.772030290962725\n",
      "Eval Mean: -61.282405503011184\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 210\n",
      "Step: 100562\n",
      "Evaluation Reward: -63.76340673786489\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -36.09667780501251\n",
      "Eval Mean: -58.09637593186415\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 211\n",
      "Step: 101110\n",
      "Evaluation Reward: 88.98586607100387\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -33.63523867862991\n",
      "Eval Mean: -53.72343385668293\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 212\n",
      "Step: 101705\n",
      "Evaluation Reward: -14.790677712066742\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -31.271628223178656\n",
      "Eval Mean: -51.73825506252271\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 213\n",
      "Step: 102705\n",
      "Evaluation Reward: -32.40039447802694\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -30.657498081393413\n",
      "Eval Mean: -51.18631454659616\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 214\n",
      "Step: 103705\n",
      "Evaluation Reward: -28.993691677063747\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -31.229982539170404\n",
      "Eval Mean: -49.26690291668533\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 215\n",
      "Step: 104705\n",
      "Evaluation Reward: -14.367648578819423\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -30.878832154866917\n",
      "Eval Mean: -46.69672717901199\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 216\n",
      "Step: 105705\n",
      "Evaluation Reward: -16.09648343717945\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -29.06521040903462\n",
      "Eval Mean: -44.49870472892968\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 217\n",
      "Step: 106705\n",
      "Evaluation Reward: -15.407068799926387\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -27.165355188016736\n",
      "Eval Mean: -41.07472314747813\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 218\n",
      "Step: 107705\n",
      "Evaluation Reward: -22.057612645737404\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -26.422126477793945\n",
      "Eval Mean: -38.703424240538624\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 219\n",
      "Step: 108403\n",
      "Evaluation Reward: -19.383272427175545\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -23.99511079165065\n",
      "Eval Mean: -37.26461224652417\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 220\n",
      "Step: 109403\n",
      "Evaluation Reward: 5.115766360816459\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -22.78384254652543\n",
      "Eval Mean: -35.03706666089506\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 221\n",
      "Step: 109793\n",
      "Evaluation Reward: 7.683477766517334\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -18.62589744952366\n",
      "Eval Mean: -32.06776398390366\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 222\n",
      "Step: 110793\n",
      "Evaluation Reward: 248.35948257861006\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -17.454070603506153\n",
      "Eval Mean: -28.18978874843119\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 223\n",
      "Step: 111793\n",
      "Evaluation Reward: 242.89192869893282\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -17.356034787631184\n",
      "Eval Mean: -23.844120540628975\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 224\n",
      "Step: 112117\n",
      "Evaluation Reward: 5.282748010707313\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -12.719697451901585\n",
      "Eval Mean: -20.970210699381497\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 225\n",
      "Step: 112667\n",
      "Evaluation Reward: 14.382871765181878\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -11.72674182569249\n",
      "Eval Mean: -18.847010192625834\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 226\n",
      "Step: 112840\n",
      "Evaluation Reward: -75.7512490102238\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -10.944105172755119\n",
      "Eval Mean: -18.355149655518087\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 227\n",
      "Step: 113840\n",
      "Evaluation Reward: -15.357659045010418\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -9.589758002368209\n",
      "Eval Mean: -17.845363628452287\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 228\n",
      "Step: 114637\n",
      "Evaluation Reward: 165.85322070307564\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -5.816670531263553\n",
      "Eval Mean: -14.622258944654945\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 229\n",
      "Step: 115232\n",
      "Evaluation Reward: 156.64804898485102\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: -2.313613709051898\n",
      "Eval Mean: -12.293023759269836\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 230\n",
      "Step: 116232\n",
      "Evaluation Reward: 128.7036356778654\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 0.28546867551348676\n",
      "Eval Mean: -8.824185306859452\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 231\n",
      "Step: 117232\n",
      "Evaluation Reward: -20.45843229471314\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 1.1487695454056472\n",
      "Eval Mean: -6.723384960163388\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 232\n",
      "Step: 117358\n",
      "Evaluation Reward: 33.33447276080332\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 2.333459767987055\n",
      "Eval Mean: -5.362971464760364\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 233\n",
      "Step: 118358\n",
      "Evaluation Reward: 5.269517884049142\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 3.650593421084392\n",
      "Eval Mean: -4.010918460489956\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 234\n",
      "Step: 119358\n",
      "Evaluation Reward: 195.54748460829566\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 4.865069202307657\n",
      "Eval Mean: -1.525034852131188\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 235\n",
      "Step: 120292\n",
      "Evaluation Reward: 90.89642247190612\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 7.228163196928805\n",
      "Eval Mean: 0.6976882445785502\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 236\n",
      "Step: 121249\n",
      "Evaluation Reward: 1.511149932963192\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 9.553241369354788\n",
      "Eval Mean: 1.8062106375729075\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 237\n",
      "Step: 122090\n",
      "Evaluation Reward: 4.102230361669257\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 13.189194052116248\n",
      "Eval Mean: 3.410042636982528\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 238\n",
      "Step: 122671\n",
      "Evaluation Reward: 112.83013754080238\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 15.859926277929162\n",
      "Eval Mean: 5.507204011862444\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 239\n",
      "Step: 123018\n",
      "Evaluation Reward: 245.00763528257875\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 19.579509240354877\n",
      "Eval Mean: 8.615017909414306\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 240\n",
      "Step: 124018\n",
      "Evaluation Reward: -9.607444533659418\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 21.461685360791204\n",
      "Eval Mean: 9.113729678327545\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 241\n",
      "Step: 124382\n",
      "Evaluation Reward: 185.68236041999708\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 24.60811875708635\n",
      "Eval Mean: 11.18197894067468\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 242\n",
      "Step: 125028\n",
      "Evaluation Reward: 196.83358243878996\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 26.58457987590181\n",
      "Eval Mean: 13.854897500549816\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 243\n",
      "Step: 125643\n",
      "Evaluation Reward: 265.83852626214446\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 28.921835070558714\n",
      "Eval Mean: 16.849621136932782\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 244\n",
      "Step: 126059\n",
      "Evaluation Reward: 214.9430439301192\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 31.626770165709605\n",
      "Eval Mean: 19.25996364808659\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 245\n",
      "Step: 126321\n",
      "Evaluation Reward: 179.75012386551566\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 34.60140059682063\n",
      "Eval Mean: 21.20149728591351\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 246\n",
      "Step: 126634\n",
      "Evaluation Reward: 222.52811987793302\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 37.98824259084445\n",
      "Eval Mean: 23.805753205215897\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 247\n",
      "Step: 126904\n",
      "Evaluation Reward: 196.31487466175724\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 41.42522471438693\n",
      "Eval Mean: 26.066200746623554\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 248\n",
      "Step: 127904\n",
      "Evaluation Reward: 200.57274218031924\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 43.02260882441661\n",
      "Eval Mean: 28.677258954100015\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 249\n",
      "Step: 128370\n",
      "Evaluation Reward: 199.35446318111696\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 45.58431966173001\n",
      "Eval Mean: 31.599789721598523\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 250\n",
      "Step: 128778\n",
      "Evaluation Reward: 235.77023567690992\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 48.24352224365242\n",
      "Eval Mean: 34.26373851868209\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 251\n",
      "Step: 129134\n",
      "Evaluation Reward: 225.69993763581326\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 51.08282112962925\n",
      "Eval Mean: 36.53869360248622\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 252\n",
      "Step: 129813\n",
      "Evaluation Reward: 213.5829961186325\n",
      "Best Evaluation Reward: 269.849213014366\n",
      "Train Mean: 52.87745556025679\n",
      "Eval Mean: 39.00959276857039\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 253\n",
      "Step: 130289\n",
      "Evaluation Reward: 276.39295720599284\n",
      "Best Evaluation Reward: 276.39295720599284\n",
      "Train Mean: 55.34194256250521\n",
      "Eval Mean: 41.94139125476213\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 254\n",
      "Step: 130731\n",
      "Evaluation Reward: 68.03502513603367\n",
      "Best Evaluation Reward: 276.39295720599284\n",
      "Train Mean: 58.026658836351025\n",
      "Eval Mean: 43.39911823182235\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 255\n",
      "Step: 131028\n",
      "Evaluation Reward: 209.83831909748287\n",
      "Best Evaluation Reward: 276.39295720599284\n",
      "Train Mean: 60.82523391525394\n",
      "Eval Mean: 45.62520655306181\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 256\n",
      "Step: 131265\n",
      "Evaluation Reward: 291.94490984832294\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 63.78840272746919\n",
      "Eval Mean: 48.6396531196537\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 257\n",
      "Step: 131543\n",
      "Evaluation Reward: 222.33920924093127\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 67.02942813998143\n",
      "Eval Mean: 51.25750078980464\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 258\n",
      "Step: 132197\n",
      "Evaluation Reward: 256.25744090356676\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 70.05343064977237\n",
      "Eval Mean: 53.98673034146278\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 259\n",
      "Step: 132477\n",
      "Evaluation Reward: 244.46426803170064\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 73.10435383616662\n",
      "Eval Mean: 56.786348629033974\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 260\n",
      "Step: 132745\n",
      "Evaluation Reward: 253.06244876265896\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 76.61029691960425\n",
      "Eval Mean: 59.779665306555046\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 261\n",
      "Step: 133062\n",
      "Evaluation Reward: 241.30419281626794\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 79.02032547040378\n",
      "Eval Mean: 62.43630160507739\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 262\n",
      "Step: 133409\n",
      "Evaluation Reward: 221.81115771703884\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 81.4928312342835\n",
      "Eval Mean: 65.10633032769005\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 263\n",
      "Step: 134020\n",
      "Evaluation Reward: 155.02770127387504\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 84.3807004963804\n",
      "Eval Mean: 66.90680259193415\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 264\n",
      "Step: 134295\n",
      "Evaluation Reward: 39.49955810597791\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 87.24018170614258\n",
      "Eval Mean: 65.73220157305613\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 265\n",
      "Step: 135162\n",
      "Evaluation Reward: 242.72461466229532\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 90.11564738526612\n",
      "Eval Mean: 68.59240086621175\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 266\n",
      "Step: 135482\n",
      "Evaluation Reward: 232.82404962696836\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 92.23478290050168\n",
      "Eval Mean: 71.07602019652202\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 267\n",
      "Step: 135712\n",
      "Evaluation Reward: 283.4377550962412\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 95.01512431472041\n",
      "Eval Mean: 74.17856042250838\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 268\n",
      "Step: 135875\n",
      "Evaluation Reward: -12.345769140155568\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 95.12649815419697\n",
      "Eval Mean: 74.26133147765923\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 269\n",
      "Step: 136122\n",
      "Evaluation Reward: 8.936806793795327\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 97.95599992486848\n",
      "Eval Mean: 74.48012623313991\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 270\n",
      "Step: 136225\n",
      "Evaluation Reward: 290.0098422840383\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 97.96639820498274\n",
      "Eval Mean: 77.9038009471188\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 271\n",
      "Step: 136497\n",
      "Evaluation Reward: 146.62520803369773\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 99.6794304154014\n",
      "Eval Mean: 80.38731365389181\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 272\n",
      "Step: 136792\n",
      "Evaluation Reward: -12.134954616850777\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 100.98879672016238\n",
      "Eval Mean: 80.54363729817895\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 273\n",
      "Step: 137057\n",
      "Evaluation Reward: 248.56464116151233\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 103.921329638644\n",
      "Eval Mean: 83.32471811933983\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 274\n",
      "Step: 137563\n",
      "Evaluation Reward: 269.08430411737754\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 106.78320480711619\n",
      "Eval Mean: 86.47037241266351\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 275\n",
      "Step: 138085\n",
      "Evaluation Reward: 210.60318550430355\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 109.92023674525377\n",
      "Eval Mean: 88.5664516076047\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 276\n",
      "Step: 138473\n",
      "Evaluation Reward: 207.90717542507429\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 113.21330428790122\n",
      "Eval Mean: 90.77428125789804\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 277\n",
      "Step: 138730\n",
      "Evaluation Reward: 129.86377296355226\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 116.18431784610677\n",
      "Eval Mean: 92.36123122244364\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 278\n",
      "Step: 138926\n",
      "Evaluation Reward: -5.214101067960655\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 119.41115105414674\n",
      "Eval Mean: 92.46830463533217\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 279\n",
      "Step: 139059\n",
      "Evaluation Reward: 271.4164113166859\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 119.55768541645318\n",
      "Eval Mean: 95.51541287939835\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 280\n",
      "Step: 139420\n",
      "Evaluation Reward: -40.14394508254168\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 122.52727799519116\n",
      "Eval Mean: 95.6619874964581\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 281\n",
      "Step: 139913\n",
      "Evaluation Reward: 168.45542570739556\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 124.89070401824665\n",
      "Eval Mean: 97.55972647101667\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 282\n",
      "Step: 140189\n",
      "Evaluation Reward: 6.176920320747598\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 127.86701929065858\n",
      "Eval Mean: 97.31852469842565\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 283\n",
      "Step: 140356\n",
      "Evaluation Reward: 138.91883582678875\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 127.24902894898814\n",
      "Eval Mean: 99.33623049934855\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 284\n",
      "Step: 140619\n",
      "Evaluation Reward: 237.64917334007836\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 127.34327618782397\n",
      "Eval Mean: 102.13654228790963\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 285\n",
      "Step: 141619\n",
      "Evaluation Reward: -9.093265643308271\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 129.10783426726783\n",
      "Eval Mean: 102.52136974030353\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 286\n",
      "Step: 141959\n",
      "Evaluation Reward: 256.74426702255585\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 129.47483643907103\n",
      "Eval Mean: 105.3998470434009\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 287\n",
      "Step: 142304\n",
      "Evaluation Reward: 188.70125020379345\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 131.64376108957072\n",
      "Eval Mean: 107.70916137831877\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 288\n",
      "Step: 142622\n",
      "Evaluation Reward: 226.1241977316951\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 132.7865132464067\n",
      "Eval Mean: 108.18536789739419\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 289\n",
      "Step: 142847\n",
      "Evaluation Reward: 242.40819733187138\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 135.30226366012857\n",
      "Eval Mean: 111.02261756034524\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 290\n",
      "Step: 143052\n",
      "Evaluation Reward: 255.63858528598564\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 138.03051814167347\n",
      "Eval Mean: 114.35747872830734\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 291\n",
      "Step: 143299\n",
      "Evaluation Reward: 266.58643957896777\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 140.7796073773903\n",
      "Eval Mean: 117.04998211675469\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 292\n",
      "Step: 143532\n",
      "Evaluation Reward: 277.78777178471034\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 144.0703096298449\n",
      "Eval Mean: 120.35586047107698\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 293\n",
      "Step: 143758\n",
      "Evaluation Reward: 224.9223252272513\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 147.37629594083256\n",
      "Eval Mean: 120.6424638395215\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 294\n",
      "Step: 144041\n",
      "Evaluation Reward: 284.4062558836737\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 150.48997068696488\n",
      "Eval Mean: 121.50917075096123\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 295\n",
      "Step: 144460\n",
      "Evaluation Reward: 242.56944267985224\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 153.18366010427854\n",
      "Eval Mean: 124.25744493948275\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 296\n",
      "Step: 144750\n",
      "Evaluation Reward: 255.43072539105572\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 154.4444227793896\n",
      "Eval Mean: 124.9738361382648\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 297\n",
      "Step: 144984\n",
      "Evaluation Reward: 167.81548562086732\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 157.4721656601829\n",
      "Eval Mean: 126.74213849406077\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 298\n",
      "Step: 145710\n",
      "Evaluation Reward: 272.93063164288526\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 160.4664592025457\n",
      "Eval Mean: 129.50262424446757\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 299\n",
      "Step: 146480\n",
      "Evaluation Reward: 242.8806189890169\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 162.72262466370776\n",
      "Eval Mean: 132.02149483947093\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 300\n",
      "Step: 146704\n",
      "Evaluation Reward: -21.672197452213908\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 164.01703401018378\n",
      "Eval Mean: 130.04608437443414\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 301\n",
      "Step: 146799\n",
      "Evaluation Reward: -8.334166010917002\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 161.22341125261525\n",
      "Eval Mean: 130.11141855230846\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 302\n",
      "Step: 146995\n",
      "Evaluation Reward: 8.861565015738975\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 164.10052755263868\n",
      "Eval Mean: 130.59725678470417\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 303\n",
      "Step: 147291\n",
      "Evaluation Reward: 38.77413433290573\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 167.6188561281719\n",
      "Eval Mean: 128.28650599788955\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 304\n",
      "Step: 147533\n",
      "Evaluation Reward: 207.9070154466633\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 168.36174071625788\n",
      "Eval Mean: 130.93406248412342\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 305\n",
      "Step: 147759\n",
      "Evaluation Reward: 246.3456233184535\n",
      "Best Evaluation Reward: 291.94490984832294\n",
      "Train Mean: 170.0697336362925\n",
      "Eval Mean: 131.49869083561873\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 306\n",
      "Step: 148031\n",
      "Evaluation Reward: 303.46597326421397\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 172.63772112452259\n",
      "Eval Mean: 135.14770941304187\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 307\n",
      "Step: 148253\n",
      "Evaluation Reward: 221.2659365061792\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 175.12334548103024\n",
      "Eval Mean: 137.69874263957598\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 308\n",
      "Step: 148646\n",
      "Evaluation Reward: 237.13038405100784\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 177.16517598608675\n",
      "Eval Mean: 140.35959143751995\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 309\n",
      "Step: 148961\n",
      "Evaluation Reward: -38.72883357146654\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 179.83802268056508\n",
      "Eval Mean: 140.35046966376547\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 310\n",
      "Step: 149136\n",
      "Evaluation Reward: -16.057736097151647\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 182.54883902003272\n",
      "Eval Mean: 140.8275263701726\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 311\n",
      "Step: 149375\n",
      "Evaluation Reward: 109.7889687898662\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 183.151184269261\n",
      "Eval Mean: 141.0355573973612\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 312\n",
      "Step: 149519\n",
      "Evaluation Reward: 251.28709960799773\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 181.80972659443125\n",
      "Eval Mean: 143.69633517056184\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 313\n",
      "Step: 149615\n",
      "Evaluation Reward: 151.99600610924077\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 181.41753864693962\n",
      "Eval Mean: 145.54029917643453\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 314\n",
      "Step: 149729\n",
      "Evaluation Reward: 130.83180917069922\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 181.406631817493\n",
      "Eval Mean: 147.13855418491212\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 315\n",
      "Step: 149871\n",
      "Evaluation Reward: 279.3472146294785\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 181.7807878442368\n",
      "Eval Mean: 150.07570281699512\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 316\n",
      "Step: 150028\n",
      "Evaluation Reward: 252.81737974422145\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 181.44605005698898\n",
      "Eval Mean: 152.7648414488091\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 317\n",
      "Step: 150152\n",
      "Evaluation Reward: 243.05088203452902\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 182.10519419729\n",
      "Eval Mean: 155.34942095715368\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 318\n",
      "Step: 150289\n",
      "Evaluation Reward: 225.54101275396914\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 182.29040614323546\n",
      "Eval Mean: 157.82540721115075\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 319\n",
      "Step: 150957\n",
      "Evaluation Reward: 245.90887347204972\n",
      "Best Evaluation Reward: 303.46597326421397\n",
      "Train Mean: 182.25888295447345\n",
      "Eval Mean: 160.47832867014301\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 320\n",
      "Step: 151072\n",
      "Evaluation Reward: 321.69334562896404\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 182.1760749347338\n",
      "Eval Mean: 163.64410446282446\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 321\n",
      "Step: 151291\n",
      "Evaluation Reward: 256.02845525674513\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 181.69726483687245\n",
      "Eval Mean: 166.12755423772677\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 322\n",
      "Step: 151533\n",
      "Evaluation Reward: 211.8942469919063\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 184.10490795460774\n",
      "Eval Mean: 165.76290188185968\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 323\n",
      "Step: 151793\n",
      "Evaluation Reward: 281.0692152657517\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.0715717567222\n",
      "Eval Mean: 166.1446747475279\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 324\n",
      "Step: 151954\n",
      "Evaluation Reward: 227.76378154589648\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 184.30826042323133\n",
      "Eval Mean: 168.36948508287978\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 325\n",
      "Step: 152157\n",
      "Evaluation Reward: 226.3022848357581\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.33043227814\n",
      "Eval Mean: 170.48867921358553\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 326\n",
      "Step: 152332\n",
      "Evaluation Reward: -0.11911726155821611\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 189.98323939927684\n",
      "Eval Mean: 171.24500053107215\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 327\n",
      "Step: 152563\n",
      "Evaluation Reward: 221.67736981262902\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.0100382451431\n",
      "Eval Mean: 173.61535081964863\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 328\n",
      "Step: 152662\n",
      "Evaluation Reward: 259.99085566269594\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 190.69285426845178\n",
      "Eval Mean: 174.5567271692448\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 329\n",
      "Step: 152943\n",
      "Evaluation Reward: 289.8480484137798\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 190.80777600641576\n",
      "Eval Mean: 175.8887271635341\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 330\n",
      "Step: 153128\n",
      "Evaluation Reward: 227.81133380979318\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.44186900157874\n",
      "Eval Mean: 176.87980414485338\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 331\n",
      "Step: 153259\n",
      "Evaluation Reward: 193.6775812109011\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.7080637438962\n",
      "Eval Mean: 179.0211642799095\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 332\n",
      "Step: 153443\n",
      "Evaluation Reward: 112.00851355254493\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 196.1783639990066\n",
      "Eval Mean: 179.80790468782692\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 333\n",
      "Step: 153545\n",
      "Evaluation Reward: 292.7260879773851\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 195.95587076762237\n",
      "Eval Mean: 182.6824703887603\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 334\n",
      "Step: 153790\n",
      "Evaluation Reward: 250.25608530396238\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 197.85712477715003\n",
      "Eval Mean: 183.22955639571694\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 335\n",
      "Step: 154046\n",
      "Evaluation Reward: 245.8718178385401\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 198.64005517462127\n",
      "Eval Mean: 184.77931034938328\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 336\n",
      "Step: 154187\n",
      "Evaluation Reward: -106.29890420598954\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 197.13444423897198\n",
      "Eval Mean: 183.70120980799376\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 337\n",
      "Step: 154565\n",
      "Evaluation Reward: 38.04786091131021\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 197.7517286489118\n",
      "Eval Mean: 184.04066611349015\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 338\n",
      "Step: 154653\n",
      "Evaluation Reward: 243.13356273461264\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 196.2813190799369\n",
      "Eval Mean: 185.34370036542828\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 339\n",
      "Step: 154751\n",
      "Evaluation Reward: -50.85494101358921\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.55681839780428\n",
      "Eval Mean: 182.3850746024666\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 340\n",
      "Step: 154999\n",
      "Evaluation Reward: 284.0586203348397\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 194.42890787940576\n",
      "Eval Mean: 185.32173525115158\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 341\n",
      "Step: 155233\n",
      "Evaluation Reward: 274.2852662520387\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 194.52307167193743\n",
      "Eval Mean: 186.207764309472\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 342\n",
      "Step: 155532\n",
      "Evaluation Reward: 257.57805207217785\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 195.45590094192372\n",
      "Eval Mean: 186.81520900580588\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 343\n",
      "Step: 155703\n",
      "Evaluation Reward: 159.98542696392764\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 196.04947220948281\n",
      "Eval Mean: 185.75667801282373\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 344\n",
      "Step: 155857\n",
      "Evaluation Reward: 251.24511541405474\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.9522424815466\n",
      "Eval Mean: 186.1196987276631\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 345\n",
      "Step: 156052\n",
      "Evaluation Reward: 211.18770191006394\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 194.72783740813892\n",
      "Eval Mean: 186.4340745081086\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 346\n",
      "Step: 156256\n",
      "Evaluation Reward: 26.208885503528847\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 194.63145270504006\n",
      "Eval Mean: 184.47088216436455\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 347\n",
      "Step: 156346\n",
      "Evaluation Reward: 266.6914117394027\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 191.55585235623454\n",
      "Eval Mean: 185.17464753514102\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 348\n",
      "Step: 156523\n",
      "Evaluation Reward: -10.241743998452392\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.0193296646528\n",
      "Eval Mean: 183.0665026733533\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 349\n",
      "Step: 156770\n",
      "Evaluation Reward: 8.77311783529477\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.4017894891539\n",
      "Eval Mean: 181.16068921989506\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 350\n",
      "Step: 157023\n",
      "Evaluation Reward: 254.50978482541046\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.18622992491734\n",
      "Eval Mean: 181.3480847113801\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 351\n",
      "Step: 157334\n",
      "Evaluation Reward: 198.47859431139096\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 193.2292055366738\n",
      "Eval Mean: 181.07587127813585\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 352\n",
      "Step: 157460\n",
      "Evaluation Reward: 168.66970738240428\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 191.23128614015718\n",
      "Eval Mean: 180.62673839077354\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 353\n",
      "Step: 157623\n",
      "Evaluation Reward: 211.6346072476863\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 191.60858707293335\n",
      "Eval Mean: 179.9791548911905\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 354\n",
      "Step: 157739\n",
      "Evaluation Reward: 252.8762470199848\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.71413581083826\n",
      "Eval Mean: 181.82756711002995\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 355\n",
      "Step: 157990\n",
      "Evaluation Reward: 238.29963355621905\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.90844608301225\n",
      "Eval Mean: 182.11218025461739\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 356\n",
      "Step: 158334\n",
      "Evaluation Reward: 253.32148663588006\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 189.1593932792619\n",
      "Eval Mean: 181.72594602249293\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 357\n",
      "Step: 158730\n",
      "Evaluation Reward: -27.842508560352897\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.63827712672486\n",
      "Eval Mean: 179.22412884448008\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 358\n",
      "Step: 158884\n",
      "Evaluation Reward: 272.36115980717966\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.71051039189632\n",
      "Eval Mean: 179.38516603351624\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 359\n",
      "Step: 159198\n",
      "Evaluation Reward: 279.4629424919523\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 189.02772773851814\n",
      "Eval Mean: 179.73515277811873\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 360\n",
      "Step: 159528\n",
      "Evaluation Reward: -27.088019765723075\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 189.09001350456674\n",
      "Eval Mean: 176.9336480928349\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 361\n",
      "Step: 160107\n",
      "Evaluation Reward: 245.8004083201405\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 190.16289459413466\n",
      "Eval Mean: 176.97861024787363\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 362\n",
      "Step: 160225\n",
      "Evaluation Reward: 249.8237982354223\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.57162210259008\n",
      "Eval Mean: 177.25873665305747\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 363\n",
      "Step: 160387\n",
      "Evaluation Reward: 269.60442874585283\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.70819041161667\n",
      "Eval Mean: 178.40450392777723\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 364\n",
      "Step: 160493\n",
      "Evaluation Reward: 180.9789214674465\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 184.90894786530782\n",
      "Eval Mean: 179.81929756139195\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 365\n",
      "Step: 160685\n",
      "Evaluation Reward: 248.42333759631418\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 185.07226446239866\n",
      "Eval Mean: 179.87628479073214\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 366\n",
      "Step: 161164\n",
      "Evaluation Reward: 268.50688589878604\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 185.55903080489622\n",
      "Eval Mean: 180.23311315345032\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 367\n",
      "Step: 161353\n",
      "Evaluation Reward: 291.3907132703213\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 185.83143221564268\n",
      "Eval Mean: 180.31264273519108\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 368\n",
      "Step: 161548\n",
      "Evaluation Reward: -46.94547582668936\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.71164205873117\n",
      "Eval Mean: 179.96664566832573\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 369\n",
      "Step: 161736\n",
      "Evaluation Reward: 225.71509045985616\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.56075490164042\n",
      "Eval Mean: 182.13442850498632\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 370\n",
      "Step: 162063\n",
      "Evaluation Reward: 295.58757589370197\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 191.36920211257183\n",
      "Eval Mean: 182.19020584108296\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 371\n",
      "Step: 162299\n",
      "Evaluation Reward: 116.87134912228768\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 191.30449716130647\n",
      "Eval Mean: 181.89266725196887\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 372\n",
      "Step: 162467\n",
      "Evaluation Reward: 227.11214388610398\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 191.08209706071221\n",
      "Eval Mean: 184.28513823699848\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 373\n",
      "Step: 162565\n",
      "Evaluation Reward: 257.0243198302496\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.49256273716102\n",
      "Eval Mean: 184.36973502368582\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 374\n",
      "Step: 162757\n",
      "Evaluation Reward: 262.46806758991477\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.58564316344425\n",
      "Eval Mean: 184.30357265841118\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 375\n",
      "Step: 163202\n",
      "Evaluation Reward: 15.677964799258916\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.63576188320803\n",
      "Eval Mean: 182.35432045136073\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 376\n",
      "Step: 163370\n",
      "Evaluation Reward: 184.6452942941061\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 185.85070870807934\n",
      "Eval Mean: 182.12170164005107\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 377\n",
      "Step: 163552\n",
      "Evaluation Reward: 111.68943587083785\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 185.87563725177435\n",
      "Eval Mean: 181.93995826912393\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 378\n",
      "Step: 163743\n",
      "Evaluation Reward: 196.91475078918216\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 185.02869886992568\n",
      "Eval Mean: 183.9612467876954\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 379\n",
      "Step: 164117\n",
      "Evaluation Reward: 271.2170799127334\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.97016268913464\n",
      "Eval Mean: 183.95925347365585\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 380\n",
      "Step: 164299\n",
      "Evaluation Reward: 237.56222321414137\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.7777100047177\n",
      "Eval Mean: 186.7363151566227\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 381\n",
      "Step: 164556\n",
      "Evaluation Reward: 292.61106613100515\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.33077544531153\n",
      "Eval Mean: 187.97787156085877\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 382\n",
      "Step: 164922\n",
      "Evaluation Reward: 228.7499889994748\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.86944807894773\n",
      "Eval Mean: 190.20360224764607\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 383\n",
      "Step: 165094\n",
      "Evaluation Reward: 269.35711067740147\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.34720601464443\n",
      "Eval Mean: 191.50798499615215\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 384\n",
      "Step: 165454\n",
      "Evaluation Reward: 246.91399091254718\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 191.2410320941244\n",
      "Eval Mean: 191.60063317187684\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 385\n",
      "Step: 165661\n",
      "Evaluation Reward: 255.1347643718793\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.40572791588022\n",
      "Eval Mean: 194.24291347202873\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 386\n",
      "Step: 166501\n",
      "Evaluation Reward: 25.763479707522492\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.94478025473268\n",
      "Eval Mean: 191.93310559887834\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 387\n",
      "Step: 166746\n",
      "Evaluation Reward: 190.9266548289874\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 188.98252247416573\n",
      "Eval Mean: 191.95535964513033\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 388\n",
      "Step: 166990\n",
      "Evaluation Reward: 251.0178870177293\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 189.49605188206178\n",
      "Eval Mean: 192.20429653799067\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 389\n",
      "Step: 167368\n",
      "Evaluation Reward: 261.7639863710048\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 189.8729126087099\n",
      "Eval Mean: 192.39785442838206\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 390\n",
      "Step: 167550\n",
      "Evaluation Reward: 227.6898408916366\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 187.03159913169418\n",
      "Eval Mean: 192.1183669844385\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 391\n",
      "Step: 167760\n",
      "Evaluation Reward: -12.45466697287334\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 186.3050175357657\n",
      "Eval Mean: 189.32795591892008\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 392\n",
      "Step: 168005\n",
      "Evaluation Reward: 251.59201156651983\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 186.26846624986584\n",
      "Eval Mean: 189.06599831673822\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 393\n",
      "Step: 168217\n",
      "Evaluation Reward: 252.19633444487587\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 186.43381770677973\n",
      "Eval Mean: 189.33873840891442\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 394\n",
      "Step: 168368\n",
      "Evaluation Reward: 258.105818907873\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 182.84059669383748\n",
      "Eval Mean: 189.0757340391564\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 395\n",
      "Step: 168596\n",
      "Evaluation Reward: 258.18379901583086\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 183.1264064124484\n",
      "Eval Mean: 189.23187760251622\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 396\n",
      "Step: 168760\n",
      "Evaluation Reward: -5.7207585228916145\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 180.4462573383427\n",
      "Eval Mean: 186.62036276337673\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 397\n",
      "Step: 168942\n",
      "Evaluation Reward: 22.167165103937663\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 180.57380360902206\n",
      "Eval Mean: 185.16387955820744\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 398\n",
      "Step: 169136\n",
      "Evaluation Reward: 269.52918182745486\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 178.8966570185895\n",
      "Eval Mean: 185.12986506005313\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 399\n",
      "Step: 169352\n",
      "Evaluation Reward: 255.8932747556008\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 179.26933284778679\n",
      "Eval Mean: 185.25999161771898\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 400\n",
      "Step: 169487\n",
      "Evaluation Reward: 279.36411948441287\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 177.1420191625311\n",
      "Eval Mean: 188.27035478708524\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 401\n",
      "Step: 169710\n",
      "Evaluation Reward: 287.3223259185483\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 179.73064209841053\n",
      "Eval Mean: 191.22691970637987\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 402\n",
      "Step: 169914\n",
      "Evaluation Reward: 283.5965176223805\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 179.22511216453063\n",
      "Eval Mean: 193.9742692324463\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 403\n",
      "Step: 170914\n",
      "Evaluation Reward: 218.2726846003668\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 177.4003633932755\n",
      "Eval Mean: 195.76925473512097\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 404\n",
      "Step: 171359\n",
      "Evaluation Reward: 315.0481005149439\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 177.33304410590574\n",
      "Eval Mean: 196.84066558580378\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 405\n",
      "Step: 171594\n",
      "Evaluation Reward: 305.75154925256015\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 177.46000951682942\n",
      "Eval Mean: 197.4347248451448\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 406\n",
      "Step: 172262\n",
      "Evaluation Reward: 254.462178445504\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 173.07716986940017\n",
      "Eval Mean: 196.9446868969577\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 407\n",
      "Step: 172647\n",
      "Evaluation Reward: 260.4770032408546\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 172.91205038328934\n",
      "Eval Mean: 197.33679756430448\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 408\n",
      "Step: 172857\n",
      "Evaluation Reward: -20.922040675565967\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 174.03446002953348\n",
      "Eval Mean: 194.75627331703873\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 409\n",
      "Step: 173020\n",
      "Evaluation Reward: 211.35290233660913\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 173.5927855552227\n",
      "Eval Mean: 197.25709067611947\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 410\n",
      "Step: 173186\n",
      "Evaluation Reward: 239.22227341970364\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 170.91796584250812\n",
      "Eval Mean: 199.809890771288\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 411\n",
      "Step: 173424\n",
      "Evaluation Reward: -203.6842889136235\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 170.00409747858393\n",
      "Eval Mean: 196.67515819425313\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 412\n",
      "Step: 173919\n",
      "Evaluation Reward: 242.36406538730085\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 172.14989075747016\n",
      "Eval Mean: 196.58592785204613\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 413\n",
      "Step: 174028\n",
      "Evaluation Reward: 254.49858874793745\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 172.03798557578662\n",
      "Eval Mean: 197.61095367843308\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 414\n",
      "Step: 174226\n",
      "Evaluation Reward: 233.41871985300503\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 174.65461043336592\n",
      "Eval Mean: 198.6368227852562\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 415\n",
      "Step: 174707\n",
      "Evaluation Reward: 266.9348437711309\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 177.02861589229695\n",
      "Eval Mean: 198.51269907667273\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 416\n",
      "Step: 174900\n",
      "Evaluation Reward: 278.3057342665628\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 175.45384512861355\n",
      "Eval Mean: 198.7675826218961\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 417\n",
      "Step: 175209\n",
      "Evaluation Reward: -218.5302310227441\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 178.2639834093381\n",
      "Eval Mean: 194.15177149132342\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 418\n",
      "Step: 175344\n",
      "Evaluation Reward: 308.5245407343369\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 178.09804484223432\n",
      "Eval Mean: 194.98160677112705\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 419\n",
      "Step: 175553\n",
      "Evaluation Reward: 302.9784783560824\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 179.13006555496372\n",
      "Eval Mean: 195.55230281996737\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 420\n",
      "Step: 175732\n",
      "Evaluation Reward: 290.2261961607407\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 179.4113561558721\n",
      "Eval Mean: 195.23763132528512\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 421\n",
      "Step: 175972\n",
      "Evaluation Reward: 268.9428059918094\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 179.57724497343918\n",
      "Eval Mean: 195.36677483263583\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 422\n",
      "Step: 176129\n",
      "Evaluation Reward: 272.8279825025335\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 175.75949216838978\n",
      "Eval Mean: 195.97611218774207\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 423\n",
      "Step: 176296\n",
      "Evaluation Reward: 311.8162365655588\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 173.00803770469653\n",
      "Eval Mean: 196.28358240074016\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 424\n",
      "Step: 176538\n",
      "Evaluation Reward: 132.23398256251443\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 175.6152142498265\n",
      "Eval Mean: 195.32828441090632\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 425\n",
      "Step: 176731\n",
      "Evaluation Reward: 223.82828543763057\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 175.66992060465694\n",
      "Eval Mean: 195.30354441692506\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 426\n",
      "Step: 176878\n",
      "Evaluation Reward: 166.81391133051318\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 175.2935519022793\n",
      "Eval Mean: 196.9728747028457\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 427\n",
      "Step: 177039\n",
      "Evaluation Reward: 226.86067079763046\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 175.13436665955254\n",
      "Eval Mean: 197.02470771269574\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 428\n",
      "Step: 177250\n",
      "Evaluation Reward: 265.11640773675407\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 173.45368513831835\n",
      "Eval Mean: 197.0759632334363\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Episode: 429\n",
      "Step: 177362\n",
      "Evaluation Reward: 257.76568234299305\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 171.35880638339924\n",
      "Eval Mean: 196.75513957272844\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Episode: 430\n",
      "Step: 177833\n",
      "Evaluation Reward: 212.80614780519653\n",
      "Best Evaluation Reward: 321.69334562896404\n",
      "Train Mean: 171.0903405623415\n",
      "Eval Mean: 196.60508771268246\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(agent.eval_rewards_mean)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
