{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import gym\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replay buffer for memory replay\n",
    "class ReplayBuffer():\n",
    "    \n",
    "    def __init__(self, input_size, mem_size=10000, batch_size=64):\n",
    "        self.mem_size = mem_size\n",
    "        self.index = 0\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "        self.obs_memory = np.empty((self.mem_size, *input_size), dtype=np.float32)\n",
    "        self.action_memory = np.empty((self.mem_size), dtype=np.int64)\n",
    "        self.reward_memory = np.empty((self.mem_size), dtype=np.float32)\n",
    "        self.next_obs_memory = np.empty((self.mem_size, *input_size), dtype=np.float32)\n",
    "        self.terminal_memory = np.empty((self.mem_size), dtype=np.bool)\n",
    "        \n",
    "    def add_memory(self, obs, action, reward, next_obs, done):\n",
    "        self.obs_memory[self.index] = obs\n",
    "        self.action_memory[self.index] = action\n",
    "        self.reward_memory[self.index] = reward\n",
    "        self.next_obs_memory[self.index] = next_obs\n",
    "        self.terminal_memory[self.index] = done\n",
    "        self.index += 1\n",
    "        self.index %= self.mem_size\n",
    "\n",
    "    def get_memory_batch(self):\n",
    "        idxs = np.random.choice(len(self), self.batch_size, replace=False)\n",
    "        \n",
    "        obss = self.obs_memory[idxs]\n",
    "        actions = self.action_memory[idxs]\n",
    "        rewards = self.reward_memory[idxs]\n",
    "        next_obss = self.next_obs_memory[idxs]\n",
    "        dones = self.terminal_memory[idxs]\n",
    "        \n",
    "        return obss, actions, rewards, next_obss, dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        return min(self.index, self.mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function approximator of the Q-Function\n",
    "class QNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, action_size, lr, save_dir, name):\n",
    "        super(QNN, self).__init__()\n",
    "        self.output_file = os.path.join(save_dir, name)\n",
    "        self.input_layer = nn.Linear(*input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) \n",
    "                                            for i in range(len(hidden_sizes)-1)])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], action_size)\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n",
    "        self.to(self.device)\n",
    "        \n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = state\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = F.relu(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def save(self):\n",
    "        torch.save(self.state_dict(), self.output_file)\n",
    "    \n",
    "    def load(self):\n",
    "        self.load_state_dict(torch.load(self.output_file))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent\n",
    "class DQN:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, action_size, min_epsilon, max_epsilon, epsilon_decay, \n",
    "                 gamma, lr, mem_size, batch_size, save_dir):\n",
    "        self.replay_buffer = ReplayBuffer(input_size, mem_size, batch_size)\n",
    "        self.qnn_target = QNN(input_size, hidden_sizes, action_size, lr, save_dir, name='target.pt')\n",
    "        self.qnn_online = QNN(input_size, hidden_sizes, action_size, lr, save_dir, name='online.pt')\n",
    "        \n",
    "        self.epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.gamma = gamma\n",
    "        self.action_size = action_size\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def epsilon_greedy(self, obs):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            with torch.no_grad():\n",
    "                obs = torch.from_numpy(obs).to(self.qnn_online.device).float()\n",
    "                action = np.argmax(self.qnn_online.forward(obs).detach().numpy())\n",
    "\n",
    "        else:\n",
    "            action = np.random.choice(self.action_size)\n",
    "        return action\n",
    "    \n",
    "    def decrement_epsilon(self):\n",
    "        if self.epsilon <= self.min_epsilon:\n",
    "            return\n",
    "        \n",
    "        epsilon = self.epsilon - self.epsilon_decay\n",
    "        self.epsilon = max(epsilon, self.min_epsilon)\n",
    "    \n",
    "    def add_memory(self, obs, action, reward, next_obs, done):\n",
    "        self.replay_buffer.add_memory(obs, action, reward, next_obs, done)\n",
    "    \n",
    "    def get_memory_batch(self):\n",
    "        obss, actions, rewards, next_obss, dones = self.replay_buffer.get_memory_batch()\n",
    "        device = self.qnn_online.device\n",
    "        obss = torch.from_numpy(obss).to(device)\n",
    "        actions = torch.from_numpy(actions).to(device)\n",
    "        rewards = torch.from_numpy(rewards).to(device)\n",
    "        next_obss = torch.from_numpy(next_obss).to(device)\n",
    "        dones = torch.from_numpy(dones).to(device)\n",
    "        return obss, actions, rewards, next_obss, dones\n",
    "        \n",
    "    def learn(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        self.qnn_online.optimizer.zero_grad()\n",
    "        obss, actions, rewards, next_obss, dones = self.get_memory_batch()\n",
    "        with torch.no_grad():\n",
    "            target = rewards + self.gamma * torch.max(self.qnn_target.forward(next_obss).detach(), dim=1)[0] \\\n",
    "                * torch.logical_not(dones)\n",
    "        target = target.unsqueeze(1)\n",
    "        online = self.qnn_online.forward(obss).gather(dim=1, index=actions.unsqueeze(1))\n",
    "\n",
    "        loss = self.qnn_online.loss(online, target)\n",
    "        loss.backward()\n",
    "        self.qnn_online.optimizer.step()\n",
    "        self.decrement_epsilon()\n",
    "    \n",
    "    def save(self):\n",
    "        self.qnn_online.save()\n",
    "    \n",
    "    def load(self):\n",
    "        self.qnn_online.load()\n",
    "        \n",
    "    def replace_target_network(self):\n",
    "        self.qnn_target.load_state_dict(self.qnn_online.state_dict())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "ENV = gym.make('CartPole-v1')\n",
    "INPUT_SIZE = ENV.observation_space.shape\n",
    "HIDDEN_SIZES = (12, 12)\n",
    "ACTION_SIZE = ENV.action_space.n\n",
    "EPISODES = 1500\n",
    "MIN_EPSILON=0.3\n",
    "MAX_EPSILON=1\n",
    "EPSILON_DECAY=0.0001\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.0001\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 64\n",
    "SAVE_DIR = './progress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa23d02fd43c4d48b394fa7917edd9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, epsilon: 0.7808000000000241\n",
      "Mean of last 100 sums of rewards is: 22.55\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 22.67\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 22.8\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 22.87\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 22.98\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 22.99\n",
      "--- Saving Agent ---\n",
      "Episode: 200, epsilon: 0.6080000000000432\n",
      "Mean of last 100 sums of rewards is: 17.28\n",
      "--- Replacing target network ---\n",
      "Episode: 300, epsilon: 0.4660000000000588\n",
      "Mean of last 100 sums of rewards is: 14.2\n",
      "--- Replacing target network ---\n",
      "Episode: 400, epsilon: 0.3324000000000735\n",
      "Mean of last 100 sums of rewards is: 13.36\n",
      "--- Replacing target network ---\n",
      "Episode: 500, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 17.39\n",
      "--- Replacing target network ---\n",
      "Episode: 600, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 16.84\n",
      "--- Replacing target network ---\n",
      "Episode: 700, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 16.9\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 23.11\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 23.68\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 23.78\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 23.94\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 23.99\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 24.16\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 24.62\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 24.83\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 25.16\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 25.34\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 25.59\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 25.88\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 26.27\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 26.45\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 26.8\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 27.24\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 27.59\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 27.96\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 28.66\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 28.75\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 28.99\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 29.44\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 29.94\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 29.98\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 30.61\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 31.05\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 31.55\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 31.71\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 32.11\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 32.34\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 32.52\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 33.07\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 33.51\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 34.37\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 34.82\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 35.15\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 35.57\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 35.95\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 36.37\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 36.58\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 37.39\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 37.86\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 38.08\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 38.46\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 38.82\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 39.38\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 40.07\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 40.32\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 40.58\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 40.84\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 41.45\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 41.55\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 42.1\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 42.23\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 42.68\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 43.02\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 43.47\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 43.97\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 44.57\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 44.92\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 45.25\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 45.62\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 46.44\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 46.92\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 47.31\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 47.48\n",
      "--- Saving Agent ---\n",
      "Episode: 800, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 47.48\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 47.88\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 48.44\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 48.45\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 48.61\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 48.91\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 49.04\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 49.05\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 49.08\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 49.1\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 49.12\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 49.93\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 50.53\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 50.81\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 50.99\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 51.1\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 51.72\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 52.33\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 53.03\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 53.23\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 53.35\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 53.66\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 53.81\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 54.31\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 54.33\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 54.38\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 54.46\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 54.59\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 54.86\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 55.02\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 55.06\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 55.13\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 55.19\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 55.52\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 56.23\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 56.24\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 56.59\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 57.29\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 57.89\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 58.36\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 58.53\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 58.56\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 58.63\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 59.38\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 59.92\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 60.18\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 60.48\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 60.71\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 60.98\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 61.02\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 61.03\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 61.23\n",
      "--- Saving Agent ---\n",
      "Episode: 900, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 61.23\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 61.3\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 61.48\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 61.59\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 61.77\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 61.91\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 62.39\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 62.43\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 62.6\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 62.63\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 63.12\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 64.5\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 64.65\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 64.93\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 65.91\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 66.18\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 67.56\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 68.68\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 68.98\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 69.89\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 69.97\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 70.34\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 70.81\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 70.98\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 71.66\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 72.04\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 72.38\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 72.59\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 73.21\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 73.79\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 74.26\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 74.83\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 74.87\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 75.24\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 75.98\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 76.82\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 77.44\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 78.06\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 78.25\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 78.52\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 78.76\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 79.02\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 79.22\n",
      "--- Saving Agent ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NEW BEST MEAN: 79.76\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 80.49\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 80.71\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 80.83\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 81.51\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 82.05\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 82.46\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 82.93\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 83.54\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 83.63\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 84.58\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 85.29\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 85.68\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 86.05\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 86.52\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 87.56\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 87.95\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 88.57\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 88.8\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 89.45\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 89.94\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 90.27\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 90.6\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 91.06\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 91.1\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 91.6\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 92.55\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 93.25\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 93.43\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 93.74\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 94.42\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 94.74\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 95.2\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 95.32\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 95.74\n",
      "--- Saving Agent ---\n",
      "Episode: 1000, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 95.74\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 96.48\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 97.15\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 97.47\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 98.26\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 98.58\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 99.27\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 100.04\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 100.67\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 101.22\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 102.77\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 103.05\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 104.11\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 104.3\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 104.4\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 104.76\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 105.49\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 105.97\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 107.35\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 108.61\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 109.46\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 110.75\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 111.29\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 112.1\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 112.52\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 113.98\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 114.18\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 114.32\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 114.81\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 114.88\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 115.05\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 115.32\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 115.53\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 115.93\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 116.77\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 117.97\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 119.16\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 119.23\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 119.4\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 119.89\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 120.15\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 120.58\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 120.86\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 121.17\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 121.65\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 121.81\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 122.23\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 122.73\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 122.84\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 123.83\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 123.87\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 124.67\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 125.33\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 125.59\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 125.63\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 125.75\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 125.84\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 126.16\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 126.48\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 126.69\n",
      "--- Saving Agent ---\n",
      "Episode: 1100, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 125.62\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 127.87\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 128.6\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 129.34\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 129.77\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 129.82\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 129.91\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 130.11\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 130.37\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 130.57\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 130.66\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 130.7\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 132.69\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 132.95\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 133.85\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 135.37\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 136.06\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 136.65\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 136.94\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 137.07\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 137.28\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 137.38\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 140.74\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 141.54\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 141.83\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 142.32\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 142.37\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 142.9\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 143.2\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 143.51\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 144.19\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 144.27\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 144.88\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 145.4\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 145.51\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 146.1\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 146.12\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 146.65\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 147.15\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 147.2\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 147.92\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 148.44\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 148.57\n",
      "--- Saving Agent ---\n",
      "Episode: 1200, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 148.57\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 148.62\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 148.82\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 150.1\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 151.12\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 151.17\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 152.09\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 152.32\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 152.82\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 153.68\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 153.79\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 154.13\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 154.58\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 155.82\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 156.13\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 159.29\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 159.31\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 159.49\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 159.68\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 159.93\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 161.5\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 161.81\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 162.42\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 164.39\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 165.18\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 166.79\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 167.16\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 167.68\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 167.93\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 168.05\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 168.14\n",
      "--- Saving Agent ---\n",
      "Episode: 1300, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 167.76\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 168.25\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 168.35\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 168.66\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 169.06\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 169.22\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 169.49\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 169.66\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 171.63\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 172.0\n",
      "--- Saving Agent ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NEW BEST MEAN: 172.08\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 173.88\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 175.45\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 175.81\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 176.2\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 176.42\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 176.55\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 177.0\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 177.08\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 177.24\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 177.86\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 177.97\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 178.39\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 178.69\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 178.89\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 179.8\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 181.15\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 181.19\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 181.96\n",
      "--- Saving Agent ---\n",
      "Episode: 1400, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 181.96\n",
      "--- Replacing target network ---\n",
      "--NEW BEST MEAN: 182.14\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 182.21\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 182.54\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 183.43\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 183.84\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 183.96\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 184.11\n",
      "--- Saving Agent ---\n",
      "--NEW BEST MEAN: 185.32\n",
      "--- Saving Agent ---\n",
      "Episode: 1500, epsilon: 0.3\n",
      "Mean of last 100 sums of rewards is: 184.15\n",
      "--- Replacing target network ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Main loop\n",
    "agent = DQN(INPUT_SIZE, HIDDEN_SIZES, ACTION_SIZE, \n",
    "            min_epsilon=MIN_EPSILON, max_epsilon=MAX_EPSILON, epsilon_decay=EPSILON_DECAY,\n",
    "            gamma=GAMMA, lr=LEARNING_RATE, \n",
    "            mem_size=MEMORY_SIZE, batch_size=BATCH_SIZE, save_dir=SAVE_DIR)\n",
    "\n",
    "reward_tracking = []\n",
    "best_mean = 0\n",
    "for episode in tqdm(range(EPISODES)):\n",
    "    obs, done = ENV.reset(), False\n",
    "    reward_sum = 0\n",
    "    while not done:\n",
    "        action = agent.epsilon_greedy(obs)\n",
    "        next_obs, reward, done, info = ENV.step(action)\n",
    "        is_truncated = 'TimeLimit.truncated' in info and info['TimeLimit.truncated']\n",
    "        terminal = done and (not is_truncated)\n",
    "        reward_sum += reward\n",
    "        agent.add_memory(obs, action, reward, next_obs, terminal)\n",
    "        obs = next_obs\n",
    "        agent.learn()\n",
    "    reward_tracking.append(reward_sum)\n",
    "    \n",
    "    # OUTPUT INFO\n",
    "    if (episode > 100):\n",
    "        reward_mean = np.array(reward_tracking[-100:]).mean()\n",
    "        if reward_mean > best_mean:\n",
    "            best_mean = reward_mean\n",
    "            print(f'--NEW BEST MEAN: {best_mean}')\n",
    "            print('--- Saving Agent ---')\n",
    "            agent.save()\n",
    "        if reward_mean > 475:\n",
    "            print('---GOAL REACHED---')\n",
    "            print('---SAVING AGENT---')\n",
    "            agent.save()\n",
    "            break\n",
    "    \n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f'Episode: {episode+1}, epsilon: {agent.epsilon}')\n",
    "        reward_mean = np.array(reward_tracking[-100:]).mean()\n",
    "        print(f'Mean of last 100 sums of rewards is: {reward_mean}')\n",
    "\n",
    "        \n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print('--- Replacing target network ---')\n",
    "        agent.replace_target_network()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward_tracking)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
